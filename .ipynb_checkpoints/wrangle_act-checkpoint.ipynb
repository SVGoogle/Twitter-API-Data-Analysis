{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis of Twitter API data\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Gathering Data](#gathering)\n",
    "- [Part II - Assessing Data](#assessing)\n",
    "- [Part III - Cleaning Data](#cleaning)\n",
    "- [Part IV - Data analysis](#analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "c:\\programdata\\anaconda3\\envs\\udacity\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tweepy\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "# Introduction\n",
    "The dataset that you will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user *@dog_rates*, also known as *WeRateDogs*. *WeRateDogs* is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" *WeRateDogs* has over 4 million followers and has received international media coverage.\n",
    "\n",
    "## Project Motivation\n",
    "### Context\n",
    "Goal: wrangle *WeRateDogs* Twitter data to create interesting and trustworthy analyses and visualizations. The Twitter archive is great, but it only contains very basic tweet information. Additional gathering, then assessing and cleaning is required for \"Wow!\"-worthy analyses and visualizations.\n",
    "### Data\n",
    "**Enhanced Twitter Archive**\n",
    "\n",
    "The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. One column the archive does contain though: each tweet's text, which I used to extract rating, dog name, and dog \"stage\" (i.e. doggo, floofer, pupper, and puppo) to make this Twitter archive \"enhanced.\" Of the 5000+ tweets, I have filtered for tweets with ratings only (there are 2356).\n",
    "I extracted this data programmatically, but I didn't do a very good job. The ratings probably aren't all correct. Same goes for the dog names and probably dog stages (see below for more information on these) too. You'll need to assess and clean these columns if you want to use them for analysis and visualization.\n",
    "\n",
    "## Key points\n",
    "Key points to keep in mind when data wrangling for this project:\n",
    "\n",
    "* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* Cleaning includes merging individual pieces of data according to the rules of tidy data.\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This unique rating system is a big part of the popularity of *WeRateDogs*.\n",
    "* You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gathering'></a>\n",
    "# Part I - Gathering Data\n",
    "\n",
    "The relevant data is retrieved by getting each of the three pieces of data as described below:\n",
    "\n",
    "1. The *WeRateDogs* Twitter archive, download this file manually by clicking the following link: [twitter_archive_enhanced.csv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv)\n",
    "\n",
    "2. The tweet image predictions, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. This file `image_predictions.tsv` is hosted on Udacity's servers.\n",
    "\n",
    "3. Additionaly, each tweet's retweet count and favorite (\"like\") count at minimum is gathered. Using the tweet IDs in the *WeRateDogs* Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called `tweet_json.txt` file. Each tweet's JSON data is written to its own line. Then this .txt file is read line by line into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. WeRateDogs Twitter archive\n",
    "This table contains an information on the tweets from *WeRateDogs* Twitter archive up to August 1st, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "\n",
       "   rating_denominator     name doggo floofer pupper puppo  \n",
       "0                  10  Phineas  None    None   None  None  \n",
       "1                  10    Tilly  None    None   None  None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_archive = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "df_archive.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_archive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2356 non-null   int64  \n",
      " 1   in_reply_to_status_id       78 non-null     float64\n",
      " 2   in_reply_to_user_id         78 non-null     float64\n",
      " 3   timestamp                   2356 non-null   object \n",
      " 4   source                      2356 non-null   object \n",
      " 5   text                        2356 non-null   object \n",
      " 6   retweeted_status_id         181 non-null    float64\n",
      " 7   retweeted_status_user_id    181 non-null    float64\n",
      " 8   retweeted_status_timestamp  181 non-null    object \n",
      " 9   expanded_urls               2297 non-null   object \n",
      " 10  rating_numerator            2356 non-null   int64  \n",
      " 11  rating_denominator          2356 non-null   int64  \n",
      " 12  name                        2356 non-null   object \n",
      " 13  doggo                       2356 non-null   object \n",
      " 14  floofer                     2356 non-null   object \n",
      " 15  pupper                      2356 non-null   object \n",
      " 16  puppo                       2356 non-null   object \n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image predictions of a dog breed in the tweet\n",
    "\n",
    "This table contains prediction info, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet.\n",
    "\n",
    "Created according to a neural network, can be downloaded from Udacity's servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "URL = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "# Extract file name\n",
    "file_name = URL.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "r = requests.get(URL)\n",
    "if r.ok:    \n",
    "    with open(file_name, mode='wb') as file:\n",
    "        file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the tab separated file\n",
    "df_predictions = pd.read_csv(file_name, sep='\\t')\n",
    "df_predictions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Connecting to Twitter API\n",
    "At this step with help of [Tweepy](http://www.tweepy.org/query) Python library we wil query Twitter's API for additional data beyond the data already included in the WeRateDogs Twitter archive file. This additional data will include retweet count and favorite count.\n",
    "\n",
    "In order to replicate this code cell, one needs to open a Twitter account.\n",
    "\n",
    "[Tweepy API Documentation](http://docs.tweepy.org/en/v3.2.0/api.html#API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the connection to Twitter API (requires Twitter account)\n",
    "consumer_key = os.getenv('TW_CONSUMER_KEY')\n",
    "consumer_secret = os.getenv('TW_CONSUMER_SECRET')\n",
    "\n",
    "access_token = os.getenv('TW_ACCESS_TOKEN')\n",
    "access_secret = os.getenv('TW_ACCESS_SECRET')\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "# Note the handling of Twitter rate limit may extend the tweet query time\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Tweet object data to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tweet IDs for which to gather additional data\n",
    "tweet_ids = df_archive.tweet_id.values\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "failed_tweets_dict = {}\n",
    "start = timer()\n",
    "\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as file:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    # Rate limits are divided into 15 minute intervals\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        # print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            # print(\"Success\")\n",
    "            json.dump(tweet._json, file)\n",
    "            file.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(f'Tweet id - {tweet_id} - does not exist anymore.\\n')\n",
    "            failed_tweets_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(f'Finished. Total execution time: {round((end - start) / 60, 2)} minutes\\n')\n",
    "print(f'Number of missing tweets: {len(failed_tweets_dict.items())}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Tweet object data\n",
    "\n",
    "The tweet object data is based on the tweet IDs in the `twitter-archive-enhanced.csv` and stored as a [Tweet JSON Object](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json) in a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary keys\n",
    "tweet._json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with the columns in the `twitter-archive-enhanced.csv`\n",
    "df_archive.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet._json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet._json['full_text'][:139]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the number of Retweets and Favorite count\n",
    "Code programmaticaly to count if a Tweet Object is a retweet and/or reply.\n",
    "\n",
    "#### Load JSON Tweet objects created with Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>7730</td>\n",
       "      <td>36331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>5725</td>\n",
       "      <td>31313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>3787</td>\n",
       "      <td>23588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>7895</td>\n",
       "      <td>39641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>8515</td>\n",
       "      <td>37841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  retweet_count  favorite_count\n",
       "0  892420643555336193           7730           36331\n",
       "1  892177421306343426           5725           31313\n",
       "2  891815181378084864           3787           23588\n",
       "3  891689557279858688           7895           39641\n",
       "4  891327558926688256           8515           37841"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of tweet IDs dictionaries, retweets and replies\n",
    "dict_list = []\n",
    "retweet_list = [] \n",
    "reply_list = []\n",
    "\n",
    "# Read .txt file as JSON file\n",
    "with open('tweet_json.txt', 'r') as file:    \n",
    "    for i, line in enumerate(file):       \n",
    "        # Convert to Python dictionary\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # Get tweet IDs if a tweet object is a retweet using regex\n",
    "        if re.search(r'retweeted_status', line):\n",
    "            retweet_list.append(data['id'])\n",
    "        \n",
    "        # Get reply tweet IDs\n",
    "        if data['in_reply_to_status_id']:\n",
    "            reply_list.append(data['id'])\n",
    "            \n",
    "        # Populate tweet dictionary\n",
    "        dict_list.append({'tweet_id': data['id'],\n",
    "                        'retweet_count': data['retweet_count'],\n",
    "                        'favorite_count': data['favorite_count']                        \n",
    "                        })\n",
    "# Create a DataFrame with the the new parameters\n",
    "df_stats = pd.DataFrame(dict_list, columns = ['tweet_id', 'retweet_count', 'favorite_count'])\n",
    "df_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 77)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number or retweets, number of replies\n",
    "len(retweet_list), len(reply_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>845098359547420673</td>\n",
       "      <td>RT @dog_rates: This is Bungalo. She uses that ...</td>\n",
       "      <td>7.733088e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>777641927919427584</td>\n",
       "      <td>RT @dog_rates: This is Arnie. He's a Nova Scot...</td>\n",
       "      <td>7.504293e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>855245323840757760</td>\n",
       "      <td>RT @dog_rates: Meet George. He looks slightly ...</td>\n",
       "      <td>8.421635e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>866094527597207552</td>\n",
       "      <td>RT @dog_rates: Here's a pupper before and afte...</td>\n",
       "      <td>8.378202e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>799308762079035393</td>\n",
       "      <td>RT @dog_rates: I WAS SENT THE ACTUAL DOG IN TH...</td>\n",
       "      <td>7.743144e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id                                               text  \\\n",
       "250  845098359547420673  RT @dog_rates: This is Bungalo. She uses that ...   \n",
       "767  777641927919427584  RT @dog_rates: This is Arnie. He's a Nova Scot...   \n",
       "194  855245323840757760  RT @dog_rates: Meet George. He looks slightly ...   \n",
       "137  866094527597207552  RT @dog_rates: Here's a pupper before and afte...   \n",
       "589  799308762079035393  RT @dog_rates: I WAS SENT THE ACTUAL DOG IN TH...   \n",
       "\n",
       "     retweeted_status_id  \n",
       "250         7.733088e+17  \n",
       "767         7.504293e+17  \n",
       "194         8.421635e+17  \n",
       "137         8.378202e+17  \n",
       "589         7.743144e+17  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify retweets in archive file\n",
    "mask_retweets = df_archive.tweet_id.isin(retweet_list)\n",
    "df_archive.loc[mask_retweets, ['tweet_id', 'text', 'retweeted_status_id']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>674606911342424069</td>\n",
       "      <td>The 13/10 also takes into account this impecca...</td>\n",
       "      <td>4.196984e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>831926988323639298</td>\n",
       "      <td>@UNC can confirm 12/10</td>\n",
       "      <td>2.068372e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>746906459439529985</td>\n",
       "      <td>PUPDATE: can't see any. Even if I could, I cou...</td>\n",
       "      <td>4.196984e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>840698636975636481</td>\n",
       "      <td>@0_kelvin_0 &amp;gt;10/10 is reserved for puppos s...</td>\n",
       "      <td>8.405479e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>693582294167244802</td>\n",
       "      <td>Personally I'd give him an 11/10. Not sure why...</td>\n",
       "      <td>1.198989e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "1905  674606911342424069  The 13/10 also takes into account this impecca...   \n",
       "346   831926988323639298                             @UNC can confirm 12/10   \n",
       "1016  746906459439529985  PUPDATE: can't see any. Even if I could, I cou...   \n",
       "274   840698636975636481  @0_kelvin_0 &gt;10/10 is reserved for puppos s...   \n",
       "1479  693582294167244802  Personally I'd give him an 11/10. Not sure why...   \n",
       "\n",
       "      in_reply_to_user_id  \n",
       "1905         4.196984e+09  \n",
       "346          2.068372e+07  \n",
       "1016         4.196984e+09  \n",
       "274          8.405479e+17  \n",
       "1479         1.198989e+09  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify replies in archive file\n",
    "mask_retweets = df_archive.tweet_id.isin(reply_list)\n",
    "df_archive.loc[mask_retweets, ['tweet_id', 'text', 'in_reply_to_user_id']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Sun Nov 15 22:32:08 +0000 2015',\n",
       " 'id': 666020888022790149,\n",
       " 'id_str': '666020888022790149',\n",
       " 'full_text': 'Here we have a Japanese Irish Setter. Lost eye in Vietnam (?). Big fan of relaxing on stair. 8/10 would pet https://t.co/BLDqew2Ijj',\n",
       " 'truncated': False,\n",
       " 'display_text_range': [0, 131],\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [],\n",
       "  'urls': [],\n",
       "  'media': [{'id': 666020881337073664,\n",
       "    'id_str': '666020881337073664',\n",
       "    'indices': [108, 131],\n",
       "    'media_url': 'http://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg',\n",
       "    'url': 'https://t.co/BLDqew2Ijj',\n",
       "    'display_url': 'pic.twitter.com/BLDqew2Ijj',\n",
       "    'expanded_url': 'https://twitter.com/dog_rates/status/666020888022790149/photo/1',\n",
       "    'type': 'photo',\n",
       "    'sizes': {'medium': {'w': 960, 'h': 720, 'resize': 'fit'},\n",
       "     'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "     'large': {'w': 960, 'h': 720, 'resize': 'fit'},\n",
       "     'small': {'w': 680, 'h': 510, 'resize': 'fit'}}}]},\n",
       " 'extended_entities': {'media': [{'id': 666020881337073664,\n",
       "    'id_str': '666020881337073664',\n",
       "    'indices': [108, 131],\n",
       "    'media_url': 'http://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg',\n",
       "    'url': 'https://t.co/BLDqew2Ijj',\n",
       "    'display_url': 'pic.twitter.com/BLDqew2Ijj',\n",
       "    'expanded_url': 'https://twitter.com/dog_rates/status/666020888022790149/photo/1',\n",
       "    'type': 'photo',\n",
       "    'sizes': {'medium': {'w': 960, 'h': 720, 'resize': 'fit'},\n",
       "     'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "     'large': {'w': 960, 'h': 720, 'resize': 'fit'},\n",
       "     'small': {'w': 680, 'h': 510, 'resize': 'fit'}}}]},\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 4196983835,\n",
       "  'id_str': '4196983835',\n",
       "  'name': 'WeRateDogs®',\n",
       "  'screen_name': 'dog_rates',\n",
       "  'location': '「 DM YOUR DOGS 」',\n",
       "  'description': 'Your Only Source For Professional Dog Ratings Instagram and Facebook ➪ WeRateDogs partnerships@weratedogs.com ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀',\n",
       "  'url': 'https://t.co/N7sNNHAEXS',\n",
       "  'entities': {'url': {'urls': [{'url': 'https://t.co/N7sNNHAEXS',\n",
       "      'expanded_url': 'http://weratedogs.com',\n",
       "      'display_url': 'weratedogs.com',\n",
       "      'indices': [0, 23]}]},\n",
       "   'description': {'urls': []}},\n",
       "  'protected': False,\n",
       "  'followers_count': 8769747,\n",
       "  'friends_count': 15,\n",
       "  'listed_count': 7260,\n",
       "  'created_at': 'Sun Nov 15 21:41:29 +0000 2015',\n",
       "  'favourites_count': 145933,\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': True,\n",
       "  'verified': True,\n",
       "  'statuses_count': 12082,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'is_translation_enabled': False,\n",
       "  'profile_background_color': '000000',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1218319284557905920/ntuD-LOA_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1218319284557905920/ntuD-LOA_normal.jpg',\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/4196983835/1586206146',\n",
       "  'profile_link_color': 'F5ABB5',\n",
       "  'profile_sidebar_border_color': '000000',\n",
       "  'profile_sidebar_fill_color': '000000',\n",
       "  'profile_text_color': '000000',\n",
       "  'profile_use_background_image': False,\n",
       "  'has_extended_profile': False,\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'following': False,\n",
       "  'follow_request_sent': False,\n",
       "  'notifications': False,\n",
       "  'translator_type': 'none'},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 463,\n",
       " 'favorite_count': 2423,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'possibly_sensitive': False,\n",
       " 'possibly_sensitive_appealable': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing'></a>\n",
    "# Part II - Assessing Data\n",
    "\n",
    "After gathering each of the above pieces of data, they are assessed visually and programmatically for quality and tidiness issues. Detect and document at least:\n",
    "    * (8) quality issues,\n",
    "    * (2) tidiness issues.\n",
    "    \n",
    "To meet specifications, the issues that satisfy the Project Motivation (see the Key Points header in [Introduction](#intro)) must be assessed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality assessment summary\n",
    "In `df_archive`:\n",
    "> 1. Columns `'doggo', 'floofer', 'pupper', 'puppo'` show that they have no missing values, however it is clear that 'None' in these columns are actual missing values that are not read in correctly by software. \n",
    "    * Furthermore, there are also a lot of values that are not register for any the dog stage category (all with 'None'), this means that the dog stage is also not categorized or mentioned in the tweet.\n",
    "    * And some observations have two different dog stages registered\n",
    "    * Columns `'doggo', 'floofer', 'pupper', 'puppo'` are of *object* type, could be converted to *category* type. However due to that there two dog stages in one observations, it will be kept as a string.\n",
    "\n",
    "> 2. Columns like `'tweet_id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id'`are of *float64* or *int* type, must be converted to str type to be as no mathematical operations are not expected to perform. The same must be done for `'tweet_id'` in other DataFrames.\n",
    "\n",
    "> 3. Column `'timestamp'` is of *object* type, must be converted to *datetime* type. Furthermore, these dates are formatted differently than the `'created_at'` time data from Tweet Object.\n",
    "\n",
    "> 4. Validity issues with numerator and denominator data - some values are not extracted properly according to the rating system. Also both must be coverted to *float* type\n",
    "\n",
    "In `df_predictions` and `df_stats`:\n",
    "> 6. Number of rows in predictions and archive data don't match:\n",
    "    * There are some replies or retweets \n",
    "    * Also there are also some tweets without the dog rating\n",
    "    * Some tweets are expired and must be removed\n",
    "     \n",
    "> 7. Drop redundant columns like:\n",
    "    * `'source'` which just shows the utility used to post the Tweet. For example, Tweets from the Twitter website have a source value of web.\n",
    "    * `'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp' ` after filtering out the retweet and reply tweets\n",
    "    * \n",
    "    \n",
    "> 8. Filter the `df_predictions` and add only correct and highest predictions to the master file\n",
    "    * Correct prediction formatting\n",
    "\n",
    "**Additional comments** \n",
    "\n",
    "> Consistency of column names with the [Tweet Object](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object) attribute names in Tweet Data Dictionary. This may lead to confusion if someone else wants to extend the existing dataset. Rename the columns according to Tweet Object atributes:`'timestamp'` to `'created_at'` or with `'text'`  and `'full_text'`. However it is not implement in this exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidiness assessment summary\n",
    "\n",
    "1. In `df_archive` there are separate columns `'doggo', 'floofer', 'pupper', 'puppo'` that are one variable and must be melted together into a one column called 'dog_stage'\n",
    "\n",
    "2. Merge into one dataset : Add the new retweet and favorite data from `df_stats` , valid predictions from `df_predictions` to twitter archive data in `df_archive` and create one file: `twitter-archive-master.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality: Different number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 2075, 2331)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tweets dont match\n",
    "df_archive.shape[0], df_predictions.shape[0], df_stats.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of missing tweets\n",
    "df_archive.shape[0] - df_stats.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality: Validity of the rating system data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validity issues with numerator and denominator data\n",
    "df_archive.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality: Missing values and appropriate data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_archive.sample(3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality: Datetime columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-08-01 16:23:56 +0000'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Date format from archive\n",
    "df_archive.timestamp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sun Nov 15 22:32:08 +0000 2015'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Date format from Tweet object is different (only relevant if we keep this info)\n",
    "data['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiddiness:  Dog stage columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in dog stage columns\n",
    "dog_stage_columns = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "\n",
    "for col in dog_stage_columns:\n",
    "    print(df_archive[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the dog stage columns have two values for the same observation\n",
    "index_list = list()\n",
    "for index, row in df_clean[dog_stage_columns].iterrows():\n",
    "    if row.nunique() > 1:\n",
    "        print(row.values)\n",
    "        # Collect indices with multiple dog stages\n",
    "        index_list.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "# Investigate tweet text extraction with Two stages \n",
    "df_clean.loc[index_list, dog_stage_columns + ['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality: Predictions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tweet_id  2075 non-null   int64  \n",
      " 1   jpg_url   2075 non-null   object \n",
      " 2   img_num   2075 non-null   int64  \n",
      " 3   p1        2075 non-null   object \n",
      " 4   p1_conf   2075 non-null   float64\n",
      " 5   p1_dog    2075 non-null   bool   \n",
      " 6   p2        2075 non-null   object \n",
      " 7   p2_conf   2075 non-null   float64\n",
      " 8   p2_dog    2075 non-null   bool   \n",
      " 9   p3        2075 non-null   object \n",
      " 10  p3_conf   2075 non-null   float64\n",
      " 11  p3_dog    2075 non-null   bool   \n",
      "dtypes: bool(3), float64(3), int64(2), object(4)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>543</td>\n",
       "      <td>0.059033</td>\n",
       "      <td>0.540167</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1532</td>\n",
       "      <td>0.044333</td>\n",
       "      <td>0.613823</td>\n",
       "      <td>0.999956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1_dog  count       min      mean       max\n",
       "0   False    543  0.059033  0.540167  1.000000\n",
       "1    True   1532  0.044333  0.613823  0.999956"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for correct dog predictions\n",
    "df_predictions.groupby('p1_dog').agg(['count', 'min', 'mean', 'max'])['p1_conf'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>522</td>\n",
       "      <td>1.011300e-08</td>\n",
       "      <td>0.11709</td>\n",
       "      <td>0.488014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1553</td>\n",
       "      <td>1.002880e-05</td>\n",
       "      <td>0.14047</td>\n",
       "      <td>0.467678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p2_dog  count           min     mean       max\n",
       "0   False    522  1.011300e-08  0.11709  0.488014\n",
       "1    True   1553  1.002880e-05  0.14047  0.467678"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.groupby('p2_dog').agg(['count', 'min', 'mean', 'max'])['p2_conf'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p3_dog</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>576</td>\n",
       "      <td>1.740170e-10</td>\n",
       "      <td>0.056893</td>\n",
       "      <td>0.255182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1499</td>\n",
       "      <td>1.434470e-06</td>\n",
       "      <td>0.061642</td>\n",
       "      <td>0.273419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p3_dog  count           min      mean       max\n",
       "0   False    576  1.740170e-10  0.056893  0.255182\n",
       "1    True   1499  1.434470e-06  0.061642  0.273419"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.groupby('p3_dog').agg(['count', 'min', 'mean', 'max'])['p3_conf'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "golden_retriever      150\n",
       "Labrador_retriever    100\n",
       "Pembroke               89\n",
       "Chihuahua              83\n",
       "pug                    57\n",
       "chow                   44\n",
       "Samoyed                43\n",
       "toy_poodle             39\n",
       "Pomeranian             38\n",
       "malamute               30\n",
       "Name: p1, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Top 10 predicted dogs labels\n",
    "is_dog = df_predictions['p1_dog'] == True\n",
    "df_predictions.loc[is_dog, 'p1'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates tweets\n",
    "df_predictions.tweet_id.duplicated().sum(), df_archive.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if predictions contain information on the same tweets\n",
    "df_predictions[['tweet_id']].append(df_archive[['tweet_id']]).tweet_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 2075)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_archive.tweet_id.unique().shape[0], df_predictions.tweet_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "# Part III - Cleaning Data\n",
    "\n",
    "Clean each of the issues you documented while assessing.  The result should be a high quality and tidy master pandas DataFrame (or DataFrames, if appropriate). Again, the issues that satisfy the Project Motivation must be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Copy of the original data before cleaning\n",
    "df_clean = df_archive.copy()\n",
    "df_stats_clean = df_stats.copy()\n",
    "df_predictions_clean = df_predictions.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues - Convert ID columns from integer to strings\n",
    "**Define:** Convert IDs from integer to float data type df.astype('object') in `df_clean`, `df_stats_clean`, `df_predictions_clean`\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# Convert IDs in all 3 data sources\n",
    "id_columns = ['tweet_id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id']\n",
    "\n",
    "df_clean[id_columns] = df_clean[id_columns].astype('str')\n",
    "df_stats_clean['tweet_id'] = df_stats_clean['tweet_id'].astype('str')\n",
    "df_predictions_clean['tweet_id'] = df_predictions_clean['tweet_id'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_clean[id_columns].dtypes.all() == 'object'\n",
    "assert df_stats_clean['tweet_id'].dtypes == 'object'\n",
    "assert df_predictions_clean['tweet_id'].dtypes == 'object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('O'), dtype('O'), dtype('O'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify tweet ID data types to be string (object in Pandas)\n",
    "df_clean[id_columns].dtypes.all(), df_stats_clean['tweet_id'].dtypes, df_predictions_clean['tweet_id'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues - Filter Retweets and Replies\n",
    "**Define:** Filter retweets and replies from `df_archive_clean` and `df_stats_clean`\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 2331)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows before removing\n",
    "df_clean.shape[0], df_stats_clean.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert extracted IDs for retweets and replies from integer to str\n",
    "# Retweet and reply tweet ids were axtracted from Twitter API data (for df_stats)\n",
    "retweet_list = list(map(str, retweet_list))\n",
    "reply_list = list(map(str, reply_list))\n",
    "drop_list = list(set(retweet_list + reply_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows to drop from df_stats_clean\n",
    "len(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask\n",
    "mask_drop_tweets = df_stats_clean['tweet_id'].isin(drop_list)\n",
    "# Index with a mask\n",
    "df_stats_clean = df_stats_clean.loc[~mask_drop_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_stats_clean['tweet_id'].isin(drop_list).any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2091"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows after\n",
    "df_stats_clean.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code:**\n",
    "\n",
    "As the `df_stats_clean` is now filtered for the retweets, replies and does not contain the tweets that have been removed in Twitter, we can filter the `df_clean` based on the `df_stats_clean` remaining observations. \n",
    "\n",
    "Another way to filter out the would be based on the `in_reply_to_status_id` and `retweeted_status_id` in the archive table but the would be redundant, as the current method deals with the problem already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 2091)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows before removing\n",
    "df_clean.shape[0], df_stats_clean.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask and filter\n",
    "mask_tweets = df_clean['tweet_id'].isin(df_stats_clean['tweet_id'])\n",
    "df_clean = df_clean.loc[mask_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows after\n",
    "assert df_clean.shape[0] == df_stats_clean.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2091"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows after\n",
    "df_clean.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues - Convert date strings to datetime\n",
    "**Define:** Convert strings to datetime object with pd.to_datetime(). Note date format is different in `df_archive` and `df_stats`\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert str to datetime\n",
    "df_clean['timestamp'] = pd.to_datetime(df_clean['timestamp'], format='%Y-%m-%d %H:%M:%S +0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stats_clean\n",
    "#df_stats_clean['created_at'] = pd.to_datetime(df_stats['created_at'], format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "#assert df_stats_clean['created_at'].dtypes == np.dtype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_clean['timestamp'].dtypes == np.dtype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2091 entries, 0 to 2355\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   timestamp  2091 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 32.7 KB\n"
     ]
    }
   ],
   "source": [
    "df_clean[['timestamp']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness Issues - Dog Stage Columns\n",
    "**Define:** Combine dog stage columns into one column named `'dog_stage'` with str methods, replace 'None' with '', afterwards remove it with Series.str.strip()\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_stage_columns = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "df_clean[dog_stage_columns] = df_clean[dog_stage_columns].replace(to_replace='None', value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all the 'None' values are removed\n",
    "for col in dog_stage_columns:\n",
    "    assert df_clean[col].any() != 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['dog_stage'] = df_clean['doggo'] + df_clean['floofer'] + df_clean['pupper'] + df_clean['puppo']\n",
    "\n",
    "# Then format entries with multiple dog stages.\n",
    "df_clean.loc[df_clean['dog_stage'] == 'doggopupper', 'dog_stage'] = 'doggo,pupper'\n",
    "df_clean.loc[df_clean['dog_stage'] == 'doggopuppo', 'dog_stage'] = 'doggo,puppo'\n",
    "df_clean.loc[df_clean['dog_stage'] == 'doggofloofer', 'dog_stage'] = 'doggo,floofer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty space character\n",
    "df_clean['dog_stage'] = df_clean['dog_stage'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 1756\n",
       "pupper            221\n",
       "doggo              71\n",
       "puppo              23\n",
       "floofer             9\n",
       "doggo,pupper        9\n",
       "doggo,puppo         1\n",
       "doggo,floofer       1\n",
       "Name: dog_stage, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['dog_stage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define:** Convert str to category with df.astype('category')\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['dog_stage'] = df_clean['dog_stage'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all the 'None' values are removed'\n",
    "assert df_clean['dog_stage'].dtypes == 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2091 entries, 0 to 2355\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype   \n",
      "---  ------   --------------  -----   \n",
      " 0   doggo    2091 non-null   category\n",
      " 1   floofer  2091 non-null   category\n",
      " 2   pupper   2091 non-null   category\n",
      " 3   puppo    2091 non-null   category\n",
      "dtypes: category(4)\n",
      "memory usage: 104.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Verify that the dog stage columns are converted properly\n",
    "df_clean[dog_stage_columns].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2091, 18)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues - Convert rating columns to float\n",
    "**Define:** Convert numerator and denumenator from integer to float data type df.astype('float')\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[['rating_numerator', 'rating_denominator']] = df_clean[['rating_numerator', 'rating_denominator']].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_clean[['rating_numerator', 'rating_denominator']].dtypes.all() == 'float'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_numerator      float64\n",
       "rating_denominator    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[['rating_numerator', 'rating_denominator']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues - Extract correct denominator values\n",
    "**Define:** Read denominator values from tweet text column with Series.str.extract(regex)\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = df_clean.text.str.extract('(\\d+)/(10)', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2 = df_clean.text.str.extract('((?:\\d+\\.)?\\d+)\\/(\\d+)', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12      484\n",
       "10      436\n",
       "11      414\n",
       "13      284\n",
       "9       153\n",
       "8        98\n",
       "7        51\n",
       "14       40\n",
       "5        34\n",
       "6        32\n",
       "3        19\n",
       "4        15\n",
       "2         9\n",
       "1         4\n",
       "0         1\n",
       "27        1\n",
       "420       1\n",
       "75        1\n",
       "1776      1\n",
       "26        1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0      484\n",
       "10.0      435\n",
       "11.0      413\n",
       "13.0      283\n",
       "9.0       153\n",
       "8.0        98\n",
       "7.0        52\n",
       "14.0       39\n",
       "5.0        34\n",
       "6.0        32\n",
       "3.0        19\n",
       "4.0        16\n",
       "2.0         9\n",
       "1.0         5\n",
       "24.0        1\n",
       "27.0        1\n",
       "84.0        1\n",
       "0.0         1\n",
       "420.0       1\n",
       "75.0        1\n",
       "80.0        1\n",
       "60.0        1\n",
       "44.0        1\n",
       "26.0        1\n",
       "144.0       1\n",
       "88.0        1\n",
       "121.0       1\n",
       "99.0        1\n",
       "204.0       1\n",
       "1776.0      1\n",
       "45.0        1\n",
       "165.0       1\n",
       "50.0        1\n",
       "Name: rating_numerator, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues - Drop unnecessary columns\n",
    "**Define:** Remove columns that are not need for the analysis with df.drop()\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2091, 8)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = list(['source', 'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp', 'doggo', 'floofer', 'pupper', 'puppo'])\n",
    "\n",
    "df_clean = df_clean.drop(columns_to_drop, axis='columns')\n",
    "\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2091 entries, 0 to 2355\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   tweet_id            2091 non-null   object        \n",
      " 1   timestamp           2091 non-null   datetime64[ns]\n",
      " 2   text                2091 non-null   object        \n",
      " 3   expanded_urls       2087 non-null   object        \n",
      " 4   rating_numerator    2091 non-null   int64         \n",
      " 5   rating_denominator  2091 non-null   int64         \n",
      " 6   name                2091 non-null   object        \n",
      " 7   dog_stage           2091 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(5)\n",
      "memory usage: 227.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_drop:\n",
    "    assert col not in df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'timestamp', 'text', 'expanded_urls', 'rating_numerator',\n",
       "       'rating_denominator', 'name', 'dog_stage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues - Format Dog prediction labels\n",
    "**Define:** use chained str atributes on string Series like: str.lower().str.replace().str.title()\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format prediction columns\n",
    "pred_id = ['p1', 'p2', 'p3']\n",
    "\n",
    "df_predictions_clean[pred_id] = df_predictions_clean[pred_id].apply(lambda x: x.str.lower().str.replace('_', ' ').str.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all words ar capitalized\n",
    "assert df_predictions_clean[pred_id].applymap(lambda x: x[0].isupper() or x[1].isupper()).all().all()\n",
    "\n",
    "# Verify that '_' is removed\n",
    "assert df_predictions_clean[pred_id].apply(lambda x: x.str.contains('_')).all().all() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welsh Springer Spaniel</td>\n",
       "      <td>Collie</td>\n",
       "      <td>Shetland Sheepdog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Redbone</td>\n",
       "      <td>Miniature Pinscher</td>\n",
       "      <td>Rhodesian Ridgeback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Shepherd</td>\n",
       "      <td>Malinois</td>\n",
       "      <td>Bloodhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rhodesian Ridgeback</td>\n",
       "      <td>Redbone</td>\n",
       "      <td>Miniature Pinscher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miniature Pinscher</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>Doberman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       p1                  p2                   p3\n",
       "0  Welsh Springer Spaniel              Collie    Shetland Sheepdog\n",
       "1                 Redbone  Miniature Pinscher  Rhodesian Ridgeback\n",
       "2         German Shepherd            Malinois           Bloodhound\n",
       "3     Rhodesian Ridgeback             Redbone   Miniature Pinscher\n",
       "4      Miniature Pinscher          Rottweiler             Doberman"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions_clean[pred_id].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness Issues - Combine data \n",
    "**Define:** Combine into one master Dataframe and store as \n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions_clean[pred_id].apply(lambda x: x.str.contains('_')).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in pred_id:\n",
    "    is_dog = df_predictions[f'{pred}_dog'] == True\n",
    "    print(df_predictions.loc[is_dog, pred].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh Springer Spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>Collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland Sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>Miniature Pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian Ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh Springer Spaniel  0.465074    True              Collie   \n",
       "1        1                 Redbone  0.506826    True  Miniature Pinscher   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland Sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian Ridgeback  0.072010    True  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions_clean.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues - Select a Dog prediction \n",
    "**Define:** Choose a prediction of a dog label with df.apply(function) based on the following criteria that:\n",
    "   * Firstly, a dog is actually predicted by neural network.\n",
    "        * Secondly, probability of the prediction is higher than 20%.\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select a prediction \n",
    "\n",
    "\n",
    "def select_prediction(df):    \n",
    "    if df['p1_dog'] and df['p2_dog'] > 0.2:\n",
    "        return df['p1']        \n",
    "    elif df['p2_dog'] and df['p2_dog'] > 0.2:\n",
    "        return df['p2']    \n",
    "    elif df['p2_dog'] and df['p2_dog'] > 0.2:\n",
    "        return df['p3']\n",
    "    else:\n",
    "        return 'Not a dog'\n",
    "    \n",
    "\n",
    "df_predictions_clean['Prediction'] = df_predictions_clean.apply(select_prediction, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not a dog             522\n",
       "Golden Retriever      164\n",
       "Labrador Retriever     99\n",
       "Pembroke               88\n",
       "Chihuahua              76\n",
       "Pug                    51\n",
       "Toy Poodle             42\n",
       "Samoyed                37\n",
       "Pomeranian             37\n",
       "Chow                   35\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions_clean['Prediction'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analysis'></a>\n",
    "# Part IV - Analyzing Data\n",
    "Storing, Analyzing, and Visualizing Data\n",
    "\n",
    "Reporting of the project:\n",
    "  1. Summary of data wrangling efforts are reported in `wrangle_report.html`.\n",
    "  2. Summary of data analyses and visualizations are reported in `act_report.html`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "\n",
    "Store the clean DataFrame(s) in a CSV file with the main one named `twitter_archive_master.csv`. If additional files exist because multiple tables are required for tidiness, name these files appropriately. Additionally, you may store the cleaned data in a SQLite database (which is to be submitted as well if you do)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
